---
title: "A-Z"
icon: "book"
---
import { GlossaryCard } from '/snippets/GlossaryCard.jsx'
import { GlossaryImageProcessor } from '/snippets/GlossaryImageProcessor.jsx'

<GlossaryImageProcessor />


## A

<GlossaryCard
  term="Agent Observability"
  category="A"
  link={{ href: "https://www.getmaxim.ai/demo", text: "Schedule a demo to learn more about Maxim's Agent Observability Platform" }}
>
  [Agent observability](https://www.ibm.com/think/insights/ai-agent-observability) is the practice of monitoring, tracing, and analyzing the internal states, decision-making processes, and outputs of AI agents in real-time including any interactions that the AI agent may have with large language models and external tools.
  <br />
  <br />
 
  **Additional Resources:**
  - [Maxim's AI Agent Observability Platform](https://www.getmaxim.ai/products/agent-observability)
  - [Learn more about Observability Concepts](https://www.getmaxim.ai/docs/tracing/concepts)
</GlossaryCard>


<GlossaryCard
  term="Agentic workflow"
  category="A"
 
>
  An [agentic workflow](https://www.ibm.com/think/topics/agentic-workflows) is an AI-driven process in which autonomous AI agents make decisions, call external tools, execute tasks, and coordinate actions with minimal human intervention to achieve specific goals. These workflows employ detailed instructions and operational sequences to solve complex tasks across diverse domains.
  <br />
  <br />
 
  **Additional Resources:**
  - [Evaluating Agentic Workflows: The Essential Metrics That Matter](https://www.getmaxim.ai/blog/evaluating-agentic-workflows)
</GlossaryCard>

<GlossaryCard
  term="AI Gateway"
  category="A"
  link={{ href: "https://www.getmaxim.ai/bifrost", text: "Learn more about Bifrost- the fastest LLM Gateway"}}
>
  An [AI Gateway](https://konghq.com/blog/enterprise/what-is-an-ai-gateway) is a specialized middleware layer designed explicitly for managing and securing interactions with Large Language Models and other AI-powered services. It sits between applications and AI models (like ChatGPT, Gemini, Claude), handling essential functions such as request routing, authentication, authorization, rate limiting, and traffic monitoring. 
  <br />
  <br />
  **Key Capabilities:**
  - *Unified API Abstraction*: Provides a single, consistent interface to access multiple AI providers, preventing vendor lock-in and simplifying integration.
  - *Security and Compliance*: Enforces managed identities and PII (Personally Identifiable Information) redaction to prevent unauthorized data exposure.
  - *Traffic & Policy Management*: Controls costs and performance through rate limiting, smart request routing, and automated model fallbacks.
  - *Observability & Cost Governance*: Centralizes the tracking of token usage, quotas, and error rates to provide clear oversight of AI spend.
  - *Model Orchestration*: Centralizes management of multiple AI models including access controls, monitoring, and deployment.
 
  **Additional Resources:**
  - [Bifrost- the fastest LLM Gateway](https://github.com/maximhq/bifrost)
  - [Bifrost vs LitLLM](https://www.getmaxim.ai/blog/bifrost-a-drop-in-llm-proxy-40x-faster-than-litellm/)
 
</GlossaryCard>

<GlossaryCard
  term="Audit Logs"
  category="A"
 >
  [Audit logs](https://www.datadoghq.com/knowledge-center/audit-logging/) are chronological records that document "who, what, and when" regarding activities within a system. These logs capture events, timestamps, responsible users or services, and the specific entities affected, creating an audit trail for transparency and accountability.
  <br />
  <br />
  **Additional Resources:**
  - [Audit logs, Guardrails, Responses API support, and more](https://www.getmaxim.ai/blog/audit-logs-guardrails-responses-api-support/)
  - [Audit Logs](https://www.getmaxim.ai/docs/release-notes/Sep%202025/audit-logs#audit-logs-maxim-enterprise)
</GlossaryCard>


## C

<GlossaryCard
  term="CI/CD"
  category="C"
  link={{ href: "https://www.redhat.com/en/topics/devops/what-is-ci-cd", text: "Learn more about how Maxim helps to automate evaluations by integrating them into your CI/CD pipelines" }}
>
  [CI/CD](https://www.redhat.com/en/topics/devops/what-is-ci-cd) is the combined practices of continuous integration (CI) and continuous delivery (CD). It uses automation to bridge the gaps between development and deployments, allowing teams to release high-quality code faster and more reliably.
  <br />
  <br />
  **Additional Resources:**
  - [Prompt CI/CD Integration](https://www.redhat.com/en/topics/devops/what-is-ci-cd)

</GlossaryCard>

<GlossaryCard
  term="Cosine Similarity"
  category="C"
>
  [Cosine similarity](https://www.ibm.com/think/topics/cosine-similarity) is a mathematical metric used to measure how similar two vectors are, regardless of their size. It calculates the cosine of the angle between them, where a value of 1 means the vectors are identical in direction, and 0 means they are completely dissimilar.
 
</GlossaryCard>

## D

<GlossaryCard
  term="Distributed Tracing"
  category="D"
  link={{ href: "https://www.getmaxim.ai/docs/tracing/concepts#trace", text: "Explore Maxim's Distributed Tracing Capabilties" }}
>
  [Distributed tracing](https://www.getmaxim.ai) is a method for tracking a single request as it moves through a distributed system, recording every step between the initial request and its final response. It captures timing, relationships, errors, and events across services, helping debug, monitor, and evaluate complex workflows. Each trace contains spans (logical units of work) that reveal the detailed path of a request.
  <br />
  <br />
  **Core components:**
  - *Traces*: The end-to-end record of a single request’s journey through the system.
  - *Spans*: The fundamental unit of a trace representing a specific operation (e.g., an API call, a database query, or an LLM generation).
  - *Event*: Events mark significant points within a span or a trace recording instantaneous occurrences that provide additional context for understanding system behavior.

  **Additional Resources:**
  - [Learn more about Distributed Tracing](https://www.getmaxim.ai/docs/tracing/concepts#trace)
  - [Basics of AI Observability](https://www.getmaxim.ai/blog/basics-of-ai-observability-sessions-traces-and-spans/)

</GlossaryCard>

<GlossaryCard
  term="Drift"
  category="D"
  link={{ href: "https://www.getmaxim.ai/articles/a-comprehensive-guide-to-preventing-ai-agent-drift-over-time/", text: "Book a demo to see how Maxim helps in drift detection" }}
>
  In LLMs, [drift](https://nexla.com/ai-infrastructure/data-drift/) refers to changes in the text distribution compared to the model's initial training data, causing the training data to become less representative of real-world usage over time. This phenomenon results in degraded model performance, producing less coherent, accurate, or contextually relevant outputs.
  <br />
  <br />
  **Mitigation:**
  - *Performance Monitoring*: Comparing model predictions against "ground truth" (actual outcomes) to identify deviations.
  - *Quality Metrics*: To detect concept drift, monitor model quality using metrics such as accuracy or mean error.
  - *Observability Platforms*: Utilizing tools like [Maxim](https://www.getmaxim.ai) to track model metrics in real-time and automate the re-evaluation of production data.

  **Additional Resources:**
  - [Evaluating AI Agent performance with Dynamic Metrics](https://www.getmaxim.ai/blog/ai-agent-evaluation-metrics/)
  - [Learn how Agent Observability helps in drift detection](https://www.getmaxim.ai/docs/tracing/overview#1-comprehensive-distributed-tracing)
</GlossaryCard>


## F

<GlossaryCard
  term="F1 score"
  category="F"
>
  The [F1 score](https://arxiv.org/abs/2010.16061) is a the harmonic mean of precision and recall, providing a single metric to evaluate a model's accuracy more holistically than simple accuracy scores. It is especially useful for understanding model performance on imbalanced datasets where one class is much more frequent than another.
  <br />
  <br />
  **How is it calculated:**
  ![F1 Score Formula|200x70](/glossary/glossary-assets/f1score.avif)
</GlossaryCard>


## G


<GlossaryCard 
  term="Guardrails"
  category="G"
  link={{ href: "https://www.getmaxim.ai/demo", text: "Schedule a demo to lean more abput Bifrost" }}
>
  [Guardrails](https://www.ibm.com/think/topics/ai-guardrails) are safety mechanisms designed to ensure artificial intelligence applications, particularly large language models (LLMs), deliver trustworthy outputs while protecting against vulnerabilities such as harmful content, sensitive data exposure, and malicious prompt engineering practices like jailbreaking or injection attacks.
  <br />
  <br />
  **Types of Guardrails:**
  - *Appropriateness Guardrails*: Check if the content generated by AI agent is toxic, harmful, biased, or based on stereotypes and filter out any such inappropriate content before it reaches customers
  - *Hallucination Guardrails*: Ensure that AI-generated content doesn't contain information that is factually wrong or misleading
  - *Regulatory Compliance Guardrails*: Validate that generated content meets regulatory requirements, whether those requirements are general or specific to the industry or use case.
  - *Security Guardrails*: Ensure the app complies with laws and regulations, handling personal data and protecting individuals' rights.

  **Additional Resources:**
  - [See how Maxim's Bifrost integrates with leading guardrail providers to offer comprehensive protection](https://docs.getbifrost.ai/enterprise/guardrails#supported-guardrail-providers).
  - [Learn more about Guardrails](https://docs.getbifrost.ai/enterprise/guardrails#overview)
</GlossaryCard>


## H 

<GlossaryCard
  term="Hallucination"
  category="H"
  link={{ href: "https://www.getmaxim.ai", text: "Learn more Abot Maxim AI" }}
>
  [AI hallucinations](https://www.ibm.com/think/topics/ai-hallucinations) occur when a large language model (LLM) perceives patterns or objects that are nonexistent, creating nonsensical or inaccurate outputs. Large language models are prone to hallucinations, generating plausible yet nonfactual content, which raises significant concerns over the reliability of LLMs in real-world.
  <br />
  <br />
  **Detection and mitigation:**
  - *Automated Evaluations*: Utilizing scalable frameworks such as "LLM-as-a-Judge," statistical metrics, and reference-based scoring to identify non-factual content.
  - *Human-in-the-loop evaluations*: Leveraging domain experts to validate outputs for contextual relevance and subjective accuracy that automated tools might miss.
  - *Real-Time Monitoring and Observability*: Implementing continuous monitoring of production logs and agent traces. 

  **Additional Resources:**
  - [See how you can build robust Evaluation Pipelines with Maxim AI](https://www.getmaxim.ai/docs/online-evals/via-ui/set-up-auto-evaluation-on-logs)
  - [LLM hallucination detection with Maxim AI](https://www.getmaxim.ai/blog/llm-hallucination-detection/)
</GlossaryCard>



## L 

<GlossaryCard
  term="Latency"
  category="L"
>
  [Latency](https://www.ibm.com/think/topics/latency) is a measurement of delay in a system. Network latency is the amount of time it takes for data to travel from one point to another across a network. 
  <br />
  A network with high latency will have slower response times, while a low-latency network will have faster response times.
</GlossaryCard>


## M

<GlossaryCard
  term="MCP server"
  category="M"
>
  [MCP server](https://en.wikipedia.org/wiki/Model_Context_Protocol) is the external service that provides context, data, or capabilities to the LLM using a standardized protocol. It acts as a bridge between the AI and external systems such as databases, local files, or web APIs translating complex data into a format the LLM can immediately process and use.
</GlossaryCard>


## N 

<GlossaryCard
  term="Noisy data"
  category="N"
>
  Noise is random, irrelevant, or corrupted information within a dataset that obscures the underlying patterns or signals an AI model is trying to learn. In machine learning, noisy data introduces statistical noise, leading to unpredictable model behavior, and reduced accuracy.
</GlossaryCard>


<GlossaryCard
  term="Non Determinism"
  category="N"
>
  In computer science, non-determinism describes a system or algorithm that can produce different outputs or exhibit different behaviors across multiple runs, even when provided with the same input.
</GlossaryCard>




## P 

<GlossaryCard
  term="PII"
  category="P"
>
  Personal data, also known as personal information or [personally identifiable information (PII)](https://en.wikipedia.org/wiki/Personal_data), is any information related to an identifiable person. In the context of AI, protecting PII is a critical requirement for regulatory compliance (such as GDPR, HIPAA, and CCPA) and for maintaining user trust.
</GlossaryCard>

<GlossaryCard
  term="Precision"
  category="P"
>
  [Precision](https://en.wikipedia.org/wiki/Precision_and_recall) (also called positive predictive value) is the fraction of relevant instances among the retrieved instances. Mathematically, precision is defined as the number of true positives (Tp) over the number of true positives plus the number of false positives (Fp). Perfect precision, indicated by a value of 1, means that every object identified as positive was classified correctly and no false positives exist.
  <br />
  <br />
  **How is it calculated:**
  ![Precision Formula|400x200](/glossary/glossary-assets/precision-formula.jpeg)
</GlossaryCard>



<GlossaryCard
  term="Prompt Engineering"
  category="P"
  link={{ href: "https://www.getmaxim.ai/products/experimentation", text: "Schedule a demo to see how Maxim AI accelerates the process of Prompt Iteration" }}
>
  [Prompt engineering](https://platform.openai.com/docs/guides/prompt-engineering) is the practice of writing clear, effective instructions that guide AI models to produce accurate, consistent, and useful outputs.
  <br />
  <br />
  **Additional Resources:**
  - See how you can do [prompt experimentation](https://www.getmaxim.ai/products/experimentation) with Maxim.

</GlossaryCard>

<GlossaryCard
  term="Prompt Injection"
  category="P"
>
  [Prompt injection](https://en.wikipedia.org/wiki/Prompt_injection) is a cybersecurity exploit in which adversaries craft inputs that appear legitimate but are designed to cause unintended behavior in machine learning models, particularly large language models (LLMs).
<br/>
<br/>
  **Additional Resources:**
  - [Understanding jailbreaking and prompt-based injections](https://www.getmaxim.ai/blog/jailbreaking-prompt-injection/)

</GlossaryCard>


## R 

<GlossaryCard
  term="R Squared"
  category="R"
>
  In statistics, the [Coefficient of Determination (R Squared)](https://en.wikipedia.org/wiki/Coefficient_of_determination), is the proportion of the variation in the dependent variable that is predictable from the independent variable(s).
  <br />
  <br />
  **How is it calculated:**
  ![R-Squared Formula|200x50](/glossary/glossary-assets/rsquare-formula.png)
</GlossaryCard>

<GlossaryCard
  term="Recall"
  category="R"
>
  [Recall](https://en.wikipedia.org/wiki/Precision_and_recall) (also known as sensitivity) is the fraction of relevant instances that were retrieved. Perfect recall, indicated by a value of 1, means that every relevant observation was identified as such and no positives were ignored.
  <br />
  <br />
  **How is it calculated:**
  ![Recall Formula|250x100](/glossary/glossary-assets/recall_formula.png)
</GlossaryCard>


## S 

<GlossaryCard
  term="Semantic Caching"
  category="S"
  link={{ href: "https://www.getmaxim.ai/demo", text: "Schedule a demo to see how Bifrost helps in reducing cost and latency of models using semantic caching" }}
>
  A [semantic cache](https://learn.microsoft.com/en-us/azure/cosmos-db/gen-ai/semantic-cache) provides a way for you to use prior user prompts and LLM completions to address similar user prompts using vector similarity search. A semantic cache can reduce latency and save costs in your GenAI applications as making calls to LLMs is often the most costly and highest latency service in such applications.
</GlossaryCard>

{/* <GlossaryCard
  term="Statistical confidence"
  category="S"
>
  It is a metric used to quantify the certainty of a statistical estimate or an AI model's prediction. It represents the probability that a specific result is accurate and not due to random chance. In AI evaluation, it helps teams determine if a model’s performance (e.g., an accuracy score) is a true reflection of its capability or just a result of a specific data sample.
</GlossaryCard> */}

<GlossaryCard
  term="Stress-testing"
  category="S"
    link={{ href: "https://www.getmaxim.ai/demo", text: "Schedule a demo to see how Maxim AI helps in evaluating your agent across real-world scenarios and different user personas" }}
>
  [Stress testing](https://en.wikipedia.org/wiki/Stress_testing) is a form of deliberately intense or thorough testing, used to determine the stability of a given system, critical infrastructure or entity. It involves testing beyond normal operational capacity, often to a breaking point, in order to observe the results.
</GlossaryCard>

## T 
<GlossaryCard
  term="Throughput"
  category="T"
>
  [Throughput](https://en.wikipedia.org/wiki/Network_throughput) refers to the rate of message delivery over a communication channel in a communication network, such as TCP/IP. Throughput is usually measured in bits per second (bit/s, sometimes abbreviated bps), and sometimes in packets per second (p/s or pps) or data packets per time slot.
</GlossaryCard>

## V 

<GlossaryCard
  term="Vector Embedding"
  category="V"
>
  [Vector embeddings](https://www.ibm.com/think/topics/vector-embedding) are numerical representations of data points that translate complex information including non-mathematical data like words, images, and audio into arrays of numbers. This allows machine learning models to process and understand the semantic relationships between different pieces of data in a high-dimensional space.
</GlossaryCard>




