---
title: "Can I Curate and Evolve Datasets for Agent Evals in Maxim?"
description: "With Maxim, you can curate AI evaluation datasets from production logs, generate synthetic test data, or import from CSV and external sources. You can build datasets that reflect real usage patterns."
---

<script
  type="application/ld+json"
  dangerouslySetInnerHTML={{
    __html: JSON.stringify({
      "@context": "https://schema.org",
      "@type": "FAQPage",
      "name": "Can I Curate and Evolve Datasets for Agent Evals in Maxim?",
      "mainEntity": {
        "@type": "Question",
        "name": "Can I Curate and Evolve Datasets for Agent Evals in Maxim?",
        "acceptedAnswer": {
          "@type": "Answer",
          "text": "Curate AI evaluation datasets in Maxim from production logs, generate synthetic test data, or import from CSV and external sources. Build datasets that reflect real usage patterns."
        }
      }
    })
  }}
/>

Maxim provides three flexible ways to build and maintain evaluation datasets:
- **Curate dataset from production**: Filter real user interactions and human feedback to capture edge cases, failure modes, and high-value scenarios that reflect actual usage patterns.
- **Generate synthetically**: Create test datasets automatically with custom configurations for your use case including inputs, expected outputs, scenarios, personas, and expected steps. You can generate from scratch or use existing datasets as reference context.
- **Import existing datasets**: Bring in datasets from CSV files, external sources, or other evaluation platforms.
